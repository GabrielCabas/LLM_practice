{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3083c0",
   "metadata": {},
   "source": [
    "## Testing some Langchain utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8af277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5964d155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187106/465876993.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"deepseek-r1:1.5b\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab93e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input()\n",
    "output = llm.invoke(query, max_tokens = 20, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251597b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning = re.search(r\"<think>(.*?)</think>\", output, flags=re.DOTALL).group(1).strip()\n",
    "response = output.split(\"</think>\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5084a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabriel, an engineer in bioinformatics with expertise in deep learning applied to biology, likely explores the application of neural networks across various biological domains. His research might focus on using deep learning for analyzing DNA sequences, protein structures, and gene expression data. Key areas could include:\n",
      "\n",
      "1. **Genomics and Proteomics**: Utilizing CNNs for DNA sequence analysis and RNNs for processing protein folding patterns.\n",
      "2. **Gene Expression Analysis**: Applying models to predict RNA expression levels from microarrays or RNA-seq data.\n",
      "3. **Multi-Modal Data Integration**: Combining genomic, proteomic, and metabolomic data using multi-modal deep learning techniques.\n",
      "\n",
      "Challenges addressed might include handling noisy biological data through data augmentation and transfer learning, optimizing computational resources for large datasets, and ensuring ethical considerations regarding privacy and data ownership.\n",
      "\n",
      "His work could also extend to applications like drug discovery and personalized medicine, leveraging deep learning to predict molecular interactions. Additionally, he may explore the ethical implications of using deep learning on sensitive biological data, ensuring compliance with regulations such as GDPR.\n",
      "\n",
      "To gain a deeper understanding, exploring specific case studies or recent research papers would provide insights into Gabriel's methodologies and contributions in these areas.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162e1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c77051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187106/1627282731.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(model=\"deepseek-r1:8b\")\n"
     ]
    }
   ],
   "source": [
    "model = ChatOllama(model=\"deepseek-r1:8b\")\n",
    "prompt = [HumanMessage(\"Cual es la capital de Chile?\")]\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3136e368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Chile es **Santiago**. Si necesitas m√°s informaci√≥n sobre Chile o sus ciudades principales, ¬°h√°game saber!\n"
     ]
    }
   ],
   "source": [
    "reasoning = re.search(r\"<think>(.*?)</think>\", output.content, flags=re.DOTALL).group(1).strip()\n",
    "response = output.content.split(\"</think>\")[-1].strip()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dceee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(\n",
    "    \"Tienes que responder como si fueras Goku\"\n",
    ")\n",
    "output = model.invoke([system_msg, prompt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a025719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Claro! La capital de Chile es **Santiago**. üòÑ\n"
     ]
    }
   ],
   "source": [
    "reasoning = re.search(r\"<think>(.*?)</think>\", output.content, flags=re.DOTALL).group(1).strip()\n",
    "response = output.content.split(\"</think>\")[-1].strip()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
