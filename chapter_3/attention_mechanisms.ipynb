{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a64ad35",
   "metadata": {},
   "source": [
    "# Coding attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668e314",
   "metadata": {},
   "source": [
    "We will implement 4 different attention mechanisms.\n",
    " - simplified self-attention\n",
    " - self-attention\n",
    " - causal attention\n",
    " - multi head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05c7f9",
   "metadata": {},
   "source": [
    "## Simplified self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "429d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "867c1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy input embeddings for 6 tokens, each with an embedding size of 3\n",
    "inputs = torch.tensor(\n",
    "    [[0.42, 0.15, 0.89],\n",
    "    [0.78, 0.33, 0.21],\n",
    "    [0.12, 0.44, 0.67],\n",
    "    [0.56, 0.91, 0.73],\n",
    "    [0.34, 0.29, 0.85],\n",
    "    [0.63, 0.11, 0.49]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86543b6c",
   "metadata": {},
   "source": [
    "Attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6ef5c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5640, 0.7614, 0.3795, 0.8904, 0.5394, 0.6306])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1] # Second word\n",
    "attention_scores_2 = torch.empty(inputs.shape[0]) # 6 scores\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attention_scores_2[i] = torch.dot(x_i, query) #Dot product\n",
    "attention_scores_2 #This vector says how similar each word is to the second word\n",
    "#Second item is the greatest in the list, because is respect to himself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7855708c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1543, 0.1880, 0.1283, 0.2139, 0.1506, 0.1649])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2 = torch.softmax(attention_scores_2, dim=0) #Now sum to 1\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "df48f105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5017, 0.3981, 0.6277])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attention_weights_2[i] * x_i\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fc97b",
   "metadata": {},
   "source": [
    "This is the context vector for only the item 2 (query).\n",
    "\n",
    "Now, we would like to have all context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "837e284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4657, 0.3874, 0.6732],\n",
       "        [0.5017, 0.3981, 0.6277],\n",
       "        [0.4606, 0.4091, 0.6722],\n",
       "        [0.4790, 0.4538, 0.6663],\n",
       "        [0.4641, 0.3983, 0.6740],\n",
       "        [0.4861, 0.3826, 0.6464]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = inputs @ inputs.T  # Shape (6, 6)\n",
    "print(attention_scores.shape)\n",
    "attention_weights = torch.softmax(attention_scores, dim=-1)  # Shape (6,\n",
    "print(attention_weights.shape)\n",
    "context_vectors = attention_weights @ inputs\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57805f",
   "metadata": {},
   "source": [
    "So, the steps are:\n",
    " - **Attention Scores**: Raw similarity between words (dot product)\n",
    " - **Attention Weights**: Normalized scores that sum to 1 (softmax)  \n",
    " - **Context Vectors**: Weighted combination of all words (final representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052d839",
   "metadata": {},
   "source": [
    "## Attention with trainable parameters\n",
    "\n",
    "Now, let's compute attention weights with trainable parameters.\n",
    "We will introduce three matrices:\n",
    " - W_q: query\n",
    " - W_k: key\n",
    " - W_v: value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f26021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1] #Input of embedding size (3)\n",
    "d_out = 2 #Output of embedding size (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74f819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_q = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_k = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_v = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f023a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = x_2 @ W_q\n",
    "key_2 = x_2 @ W_k\n",
    "value_2 = x_2 @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7a1c460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0057, 0.2636]), tensor([0.8479, 1.1501]), tensor([0.9898, 0.8750]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2, key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21072402",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328fcbb",
   "metadata": {},
   "source": [
    "Okay, let's get the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0211f0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9975, 1.1559, 0.6061, 1.3122, 0.9206, 1.0459])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec13c09",
   "metadata": {},
   "source": [
    "An then the attention weights. We will normalize by sqrt(len(keys)). This tries to improve the training performance by avoiding small gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4464dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1637, 0.1831, 0.1241, 0.2045, 0.1551, 0.1694])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1] ** 0.5, dim=-1)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9972d",
   "metadata": {},
   "source": [
    "Let's get the context vector for the second word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c1611b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1408, 0.8940])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbfef48",
   "metadata": {},
   "source": [
    "Query key and value are borrowed from the domain of information retrieval and databases, where similar concepts are used to store, search and retrieve information.\n",
    "\n",
    "Query is analogous to a search query ina database. It represents the current item.\n",
    "\n",
    "Key is like a database key used for indexing and searching. Each item in the input sequence has an associated key.\n",
    "\n",
    "Value is the value in a key-value pair in a database. Represents the actual content of the input items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be819df5",
   "metadata": {},
   "source": [
    "## Compact self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccf63c",
   "metadata": {},
   "source": [
    "We will use a class to summary the concept of self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "794dcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
    "        context_vector = attn_weights @ values\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b372e562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0814, 0.6917],\n",
      "        [1.0830, 0.6922],\n",
      "        [1.0808, 0.6916],\n",
      "        [1.0915, 0.7033],\n",
      "        [1.0821, 0.6927],\n",
      "        [1.0805, 0.6898]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v1 = SelfAttentionV1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65e8e4",
   "metadata": {},
   "source": [
    "Let's do the same but using linear layers. These use more optimized initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "154e4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out)\n",
    "        self.W_key = nn.Linear(d_in, d_out)\n",
    "        self.W_value = nn.Linear(d_in, d_out)\n",
    "    def forward(self, x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim = -1)\n",
    "        context_vector = attn_weights @ values\n",
    "        return context_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e5ffa2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0234,  0.0849],\n",
      "        [-0.0242,  0.0799],\n",
      "        [-0.0235,  0.0848],\n",
      "        [-0.0240,  0.0821],\n",
      "        [-0.0235,  0.0848],\n",
      "        [-0.0238,  0.0823]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v2 = SelfAttentionV2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869b90c",
   "metadata": {},
   "source": [
    "## Hiding future words with causal attention\n",
    "\n",
    "For many LLM tasks (as GPT), you will want the self-attention mechanism to consider only the tokens that appear prior the current position.\n",
    "\n",
    "This is causal/masked attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "899b4905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2368,  0.2338,  0.1602,  0.3064,  0.2241,  0.2229],\n",
       "        [ 0.0069, -0.1251,  0.0575, -0.0078,  0.0246, -0.0760],\n",
       "        [ 0.5268,  0.4681,  0.3771,  0.6750,  0.5057,  0.4633],\n",
       "        [ 0.5142,  0.3672,  0.4041,  0.6475,  0.5060,  0.3962],\n",
       "        [ 0.3489,  0.3237,  0.2443,  0.4488,  0.3331,  0.3154],\n",
       "        [ 0.0286, -0.0277,  0.0417,  0.0299,  0.0347, -0.0081]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "key = sa_v2.W_key(inputs)\n",
    "value = sa_v2.W_value(inputs)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "attn_scores #Squared matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3537c",
   "metadata": {},
   "source": [
    "Let's replace the upper triangle with -inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0501c8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2368,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 0.0069, -0.1251,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 0.5268,  0.4681,  0.3771,    -inf,    -inf,    -inf],\n",
       "        [ 0.5142,  0.3672,  0.4041,  0.6475,    -inf,    -inf],\n",
       "        [ 0.3489,  0.3237,  0.2443,  0.4488,  0.3331,    -inf],\n",
       "        [ 0.0286, -0.0277,  0.0417,  0.0299,  0.0347, -0.0081]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal = 1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f66d2",
   "metadata": {},
   "source": [
    "Now, if we use softmax, rows will sum 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9a6a1f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5233, 0.4767, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3498, 0.3356, 0.3147, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2548, 0.2296, 0.2357, 0.2799, 0.0000, 0.0000],\n",
       "        [0.2011, 0.1975, 0.1867, 0.2158, 0.1988, 0.0000],\n",
       "        [0.1681, 0.1615, 0.1696, 0.1682, 0.1688, 0.1638]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim = 1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "24cdad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1219, 0.8538],\n",
       "        [1.0589, 0.8639],\n",
       "        [1.0103, 0.7918],\n",
       "        [1.1774, 0.9110],\n",
       "        [1.1607, 0.8931],\n",
       "        [1.1172, 0.8701]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ values\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670bf39",
   "metadata": {},
   "source": [
    "Making additional attention weights with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2d35789c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2772, 0.1809, 0.2098, 0.0000, 0.2641, 0.0000],\n",
       "        [0.2204, 0.0000, 0.1833, 0.0000, 0.2151, 0.2356],\n",
       "        [0.2491, 0.1785, 0.2356, 0.3179, 0.2555, 0.1920],\n",
       "        [0.2164, 0.1898, 0.2029, 0.4159, 0.0000, 0.0000],\n",
       "        [0.2666, 0.1781, 0.2172, 0.3042, 0.2611, 0.2014],\n",
       "        [0.2523, 0.2313, 0.1935, 0.2769, 0.2388, 0.0000]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Dropout\n",
    "dropout = Dropout(0.3)\n",
    "dropout(attention_weights) #Drop some random cells (~30%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720859b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "36cb1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "            diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens],\n",
    "            -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attention_scores / keys.shape[-1] ** 0.5, dim = 1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e4cd8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim = 0)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "context_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b42a4",
   "metadata": {},
   "source": [
    "## Multi head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b6643dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e9a47ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads = 2)\n",
    "context_vecs = mha(batch)\n",
    "context_vecs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
